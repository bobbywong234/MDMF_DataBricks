{"cells":[{"cell_type":"markdown","source":["#### Data Standardization: Get Column Schema\nConnects to the ingested file and infers the column schema data types that json schema value is stored on FwkObjectMetadata table."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"abdf5cf5-bf43-49e7-9493-50575e9547c0"}}},{"cell_type":"code","source":["%run \"/Shared/MDMF/Tools/utilities\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Utilities","showTitle":true,"inputWidgets":{},"nuid":"671481d3-a7b1-48cc-8a4a-ee5d9124fae5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Obtain the parameters sent by Azure Data Factory\n#dbutils.widgets.removeAll()\n\n##source params\ndbutils.widgets.text(\"NbRunParameters\", \"\", \"\")\ndbutils.widgets.text(\"SourceInstanceURL\", \"\", \"\")\ndbutils.widgets.text(\"SourceContainerName\", \"\", \"\")\ndbutils.widgets.text(\"SourceFilePath\", \"\", \"\")\ndbutils.widgets.text(\"SourceFileExtension\", \"\", \"\")\ndbutils.widgets.text(\"SourceKeySecretName\", \"\", \"\")\ndbutils.widgets.text(\"ObjectSchema\", \"\", \"\")\ndbutils.widgets.text(\"ColumnSchema\", \"\", \"\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Widgets","showTitle":true,"inputWidgets":{},"nuid":"43b59317-47c9-4aba-8390-177dad682391"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["##source vars\nnb_run_parameters = json.loads(dbutils.widgets.get(\"NbRunParameters\"))\nsource_instance_url = dbutils.widgets.get(\"SourceInstanceURL\") \nsource_container_name = dbutils.widgets.get(\"SourceContainerName\") \nsource_file_path = dbutils.widgets.get(\"SourceFilePath\") \nsource_file_extension = dbutils.widgets.get(\"SourceFileExtension\") \nsource_key_secret_name = dbutils.widgets.get(\"SourceKeySecretName\")\nsource_object_schema = json.loads(dbutils.widgets.get(\"ObjectSchema\"))\nsource_column_schema = json.loads(dbutils.widgets.get(\"ColumnSchema\"))\n\n##derived vars\nkv_scope_name = nb_run_parameters['kvScopeName']\nservice_principal_id = nb_run_parameters['servicePrincipalId']\nservice_principal_secret_name = nb_run_parameters['servicePrincipalSecretName']\ntenant_id = nb_run_parameters['tenantId']\nsource_storage_name = return_storage_name(source_instance_url)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Variables","showTitle":true,"inputWidgets":{},"nuid":"3f7e7de7-1ea0-465c-aa81-476df7fc71b8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def remove_null(df, column2evaluate):\n    df = df.filter(f'{column2evaluate} != \"NULL\"')\n    df = df.filter(f'{column2evaluate} != \"\"')\n    df = df.na.drop(subset=[column2evaluate])\n    return df\n\n#Class that will evaluate cast for specific column of each datatype \n\nclass DataTypecheck: # it works for pyspark dataframe only\n\n    def __init__(self, dataframe):\n        #when class is initialized store dataframe to shorter names\n        self.df = dataframe\n        self.acceptance = 0.1\n\n    #functions to cast schemas\n    def bit(self,column2evaluate): #function to evaluate if values are boolean, 1st function to evaluate\n        \n        data_type = str(df.schema[column2evaluate].dataType)\n        if 'BooleanType' in data_type:\n            return 1\n        elif 'StringType' in data_type:   \n            df2 = self.df.select(column2evaluate)\n            df2 = remove_null(df2, column2evaluate)\n            df2 = df2.groupBy(column2evaluate).agg(count(\"*\"))\n            row_count = df2.select(column2evaluate).count()\n\n            if row_count > 3:\n    #             print(\"Not Bit\")\n                return 0\n            elif row_count < 2:\n    #             print(\"Not Bit\")\n                return 0\n            else:\n                flag = False\n                column_data_list = df2.select(column2evaluate).rdd.flatMap(lambda x: x).collect()\n                for each_data in column_data_list:\n                    if each_data in ['1', '0']:\n                        flag = True\n                    else:\n                        return 0\n\n                if flag == True:\n                    return 1\n        else:\n            return 0\n\n    def integer(self,column2evaluate): # use this function to validate for int if and only if bit failed, 2nd funct to evaluate \n        \n        data_type = str(df.schema[column2evaluate].dataType)\n        if 'IntegerType' in data_type or 'LongType' in data_type:\n            return 1\n        elif 'StringType' in data_type:   \n            self.col=column2evaluate\n            #check for null values to avoid counting more nulls\n            try:\n                df2 = remove_null(self.df, column2evaluate)\n                df3 = df2.withColumn(self.col, round(df2[self.col]).cast(IntegerType())) #round up to make sure first they are numbers\n                if df3.filter(df3[self.col].isNull()).count()>self.acceptance*(df2.count()): #if more than 70% are nulls then its sure not an integer\n                    return 0\n                else:\n                    return 1\n            except:\n                return 0\n        else:\n            return 0\n\n    def decimal(self,column2evaluate): #this funct should only be called if integer returned 1, 3rd function to evaluate\n        \n        data_type = str(df.schema[column2evaluate].dataType)\n        if 'DecimalType' in data_type:\n            return 1\n        elif 'StringType' in data_type:\n            self.col = column2evaluate\n            df2 = self.df\n            try:\n                df2 = remove_null(self.df, column2evaluate)\n                df3 = df2.withColumn(self.col, round(df2[self.col]).cast(IntegerType())) #round up to make sure first they are numbers\n                if df3.filter(df3[self.col].isNull()).count()>self.acceptance*(df2.count()): #if more than 70% are nulls then its sure not an integer\n                    return 0\n                else:\n                    if (self.df.filter(self.df[self.col].contains('.'))).count()==0:\n                        return 0\n                    else:\n                        return 1\n            except:\n                return 0 \n        else:\n            return 0\n\n    def biginteger(self,column2evaluate): #this function should be called if integer is validated and decimal is not 4th funct to evaluate\n        data_type = str(df.schema[column2evaluate].dataType)\n        if 'IntegerType' in data_type or 'LongType' in data_type:\n            if df.where(df[column2evaluate]>2147483647).count()>0: #check if there is a value higher than the largest int it will set it to max int\n                return 1\n            else:\n                return 0\n        elif 'StringType' in data_type: \n            self.col=column2evaluate\n            df2 = remove_null(self.df, column2evaluate)\n            df3 = self.df.withColumn(self.col, round(df2[self.col]).cast(IntegerType())) #round up to make sure first they are numbers\n            if df3.where(df3[self.col]>2147483647).count()>0: #check if there is a value higher than the largest int it will set it to max int\n                return 1\n            else:\n                return 0\n            \n        else:\n            return 0\n        \n    def date(self,column2evaluate): #if integer returned 0, bit must've returned 0 too, so we try date 5th function to evaluate\n        data_type = str(df.schema[column2evaluate].dataType)\n        if 'DateType' in data_type or 'TimestampType' in data_type:\n            return 1\n        elif 'StringType' in data_type:   \n            df2 = remove_null(self.df, column2evaluate)\n            self.col=column2evaluate\n            cont=0\n            for el in df2.select(self.col).collect(): #iterate over each value of the columns\n                try: \n                    dateutil.parser.parse(el[0]) #try to parse it to date\n                except:\n                    cont+=1 #if you cant parse it to date store the issue \n            if cont>=self.acceptance*df2.select(self.col).count():#if more than 70% of the data cant be converted to datetime this col shouldn't be datetime\n                return 0\n            else:\n                return 1\n            \n        else:\n            return 0\n\n    def datetime(self,column2evaluate): #this func should only be called after validating that date is 1 \n        data_type = str(df.schema[column2evaluate].dataType)\n        if 'TimestampType' in data_type:\n            return 1\n        elif 'StringType' in data_type:   \n            df2 = remove_null(self.df, column2evaluate)\n            self.col=column2evaluate\n            contv=0\n    #         print(self.df.select(self.col).collect()[0][0])\n    #         print((dateutil.parser.parse(self.df.select(self.col).collect()[0][0])))\n            for el in df2.select(self.col).collect():\n                try:\n                    val=(dateutil.parser.parse(el[0])) #we know that data can be parsed since date returned 1\n\n                    try:\n                        if val.hour>=0 or val.minute>=0 or (df2.withColumn(self.col, col(self.col).cast('timestamp'))): #if at least 1 value has hour or minute set to more than 1 its datetime\n                            contv+=1\n                    except:\n                        pass\n                except:#if it cant be parsed it is an empty string so we just ignore it\n                    pass\n            if contv>0: #if we registered that at least one element that is datetime has hours then we use datetime not date\n                return 1\n            else:\n                return 0\n            \n        else:\n            return 0\n\n#     def binary(self,column2evaluate):\n#         df2 = remove_null(self.df, column2evaluate)\n#         self.col=column2evaluate\n# #         df2=self.df    \n#         val=0\n#         try:\n#             df3 = df2.withColumn(self.col, df2[self.col].cast(BinaryType())) #perform casting\n#             for c in df3.select(self.col).collect():\n#                 if c[0]==None:\n#                     pass\n#                 else:\n#                     c[0].decode()\n#         except:\n#             val+=1\n    \n#         if val>0:\n#             return 1\n#         else:\n#             return 0\n\n    \n    def maxvarchar(self,column2evaluate): #we should use this function only after validating it it is not anything else \n        #this function will be evaluated second to last\n        df2 = remove_null(self.df, column2evaluate)\n        self.col=column2evaluate\n        if df2.where(length(col(self.col))>255).count()>0: #if we have at least one value higher than 255 use var char max\n            return 1\n        else:\n            return 0\n\n    def varchar(self,column2evaluate):\n        #this function should be evaluated last\n        self.col=column2evaluate\n        if self.maxvarchar(self.col)==0:\n            return 1\n\n    def remove_null(self, df, column2evaluate):\n        df = df.filter(f'{column2evaluate} != \"NULL\"')\n        df = df.filter(f'{column2evaluate} != \"\"')\n        df = df.na.drop(column2evaluate=[column])\n        return df\n    \n    def get_schema(self):\n\n        schema = []\n        cols = self.df.columns\n        \n        for n,c in enumerate(cols, 1): #Main logic to validate schemas for each column\n            \n            data_type = str(df.schema[c].dataType)\n#             print(c + \": \" + data_type)\n#             print(type(data_type))\n\n                  \n            data = {}\n            data['id'] = str(n)\n            data['name'] = c\n            \n#             if (remove_null(self.df, c)).count() == 0:\n#                 data['type']='Varchar (8000)'\n            #check if column is boolean\n            if self.bit(c) == 1:\n                data['type']='Bit'\n            elif self.decimal(c) == 1:\n                    data['type'] = 'Decimal(18,4)'\n            elif self.integer(c) == 1: #now we know this column is a number so we can check for .\n                if self.biginteger(c) == 1: #if it is not a decimal it still may be a big integer\n                    data['type']='Bigint'\n                else:\n                    data['type']='Int'\n            elif self.date(c) == 1: #if it is not an integer check it can be parsed to date \n                if self.datetime(c) == 1:\n                    data['type'] = 'Datetime'\n                else:\n                    data['type'] = 'Date'\n            else: \n                #it should definitely be a string\n                #if self.binary(c) == 1:\n                #    data['type']='Binary'          \n                if self.maxvarchar(c)==1:\n                    data['type']='Varchar(8000)'\n                else: #if its not any of those it should be this one\n                    data['type']='Varchar(255)'\n            \n            data['isSensitive'] = 'N'\n            \n            schema.append(data)\n\n        return schema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Get Column Schema Function","showTitle":true,"inputWidgets":{},"nuid":"0f44148e-e1a2-4af3-8886-9fd53afc7815"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["try:\n    #read from ingested file (with out column schema)\n    df = read_from_adls(kv_scope_name, service_principal_id, service_principal_secret_name, tenant_id, source_storage_name, source_container_name, source_file_path, source_file_extension, source_object_schema)\n    #display(df)\n    \n    if df.count() > 0:\n        #getting columnSchema from the object, limiting to 5000 records\n        columnSchema = DataTypecheck(df.limit(5000)).get_schema()\n    else:\n        columnSchema = source_column_schema\nexcept Exception as ex:\n    raise Exception('ERROR: {}'.format(ex))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Infer Column Schema From Ingested File","showTitle":true,"inputWidgets":{},"nuid":"d8f05cdb-9e5c-4fa8-96b0-d9378544fc34"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["dbutils.notebook.exit(columnSchema)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Output","showTitle":true,"inputWidgets":{},"nuid":"9fa689b8-6390-40de-8d58-bcbb7daa191d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"exit","data":"[{'id': '1', 'name': 'col1', 'type': 'Varchar(255)', 'isSensitive': 'N'}, {'id': '2', 'name': 'col2', 'type': 'Varchar(255)', 'isSensitive': 'N'}]","arguments":{},"metadata":{}}},"output_type":"display_data","data":{"text/plain":["[{'id': '1', 'name': 'col1', 'type': 'Varchar(255)', 'isSensitive': 'N'}, {'id': '2', 'name': 'col2', 'type': 'Varchar(255)', 'isSensitive': 'N'}]"]}}],"execution_count":0},{"cell_type":"code","source":["#pyspark_column_schema = format_column_schema(columnSchema)\n#print(pyspark_column_schema)\n#pyspark_column_schema = \"CustomerID INTEGER, NameStyle BOOLEAN, Title STRING, FirstName STRING, MiddleName STRING, LastName STRING, Suffix STRING, CompanyName STRING, SalesPerson STRING, EmailAddress STRING, Phone STRING, PasswordHash STRING, PasswordSalt STRING, rowguid STRING, ModifiedDate TIMESTAMP\"\n\n#df2 = read_from_adls(kv_scope_name, source_storage_name, source_key_secret_name, source_container_name, source_file_path, source_file_extension, source_object_schema, pyspark_column_schema)\n#display(df2)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85eb3a4e-45f0-44d2-8223-e24615d1b55a"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"DI_01_InferColumnSchema","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{"SourceFilePath":{"nuid":"418194ce-05de-42bb-8dd5-981a78feb157","currentValue":"ADLS/mdmfadlscl/example_text_file/Full/example_text_file_20220722184409/*.txt","widgetInfo":{"widgetType":"text","name":"SourceFilePath","defaultValue":"","label":"","options":{"widgetType":"text","validationRegex":null}}},"NbRunParameters":{"nuid":"ff9690d0-1053-46e8-9cc4-1e34ce3972ce","currentValue":"{ \"databricksWsURL\": \"https://adb-6654437332163728.8.azuredatabricks.net/\", \"tokenSecretName\": \"mdmf-databricks-token\", \"clusterId\": \"0506-163902-anion204\", \"kvScopeName\": \"mdmf-kv-scope-cl\" }","widgetInfo":{"widgetType":"text","name":"NbRunParameters","defaultValue":"","label":"","options":{"widgetType":"text","validationRegex":null}}},"ObjectSchema":{"nuid":"5eaf415c-0616-4ae5-96ca-bf283dbc466a","currentValue":"{\"extractionType\":\"Full\",\"inferColumnSchema\":\"Y\",\"headerFlag\":\"Y\",\"delimiter\":\"|\"}","widgetInfo":{"widgetType":"text","name":"ObjectSchema","defaultValue":"","label":"","options":{"widgetType":"text","validationRegex":null}}},"SourceContainerName":{"nuid":"996f86ef-1dd0-4d6a-9a2c-e3b5d973f9bd","currentValue":"transient","widgetInfo":{"widgetType":"text","name":"SourceContainerName","defaultValue":"","label":"","options":{"widgetType":"text","validationRegex":null}}},"SourceKeySecretName":{"nuid":"7290b174-053e-40c8-88c1-1c1fa78e784d","currentValue":"MDMF-Transient-StorageAccount-Key","widgetInfo":{"widgetType":"text","name":"SourceKeySecretName","defaultValue":"","label":"","options":{"widgetType":"text","validationRegex":null}}},"SourceInstanceURL":{"nuid":"93adab50-954d-4211-a575-5d842395eef4","currentValue":"https://mdmfadlscltransient.dfs.core.windows.net/","widgetInfo":{"widgetType":"text","name":"SourceInstanceURL","defaultValue":"","label":"","options":{"widgetType":"text","validationRegex":null}}},"ColumnSchema":{"nuid":"9817083b-397c-4609-a35a-6cf877c0a5e3","currentValue":"[]","widgetInfo":{"widgetType":"text","name":"ColumnSchema","defaultValue":"","label":"","options":{"widgetType":"text","validationRegex":null}}},"SourceFileExtension":{"nuid":"fb7b2d9a-12ef-4682-93b6-2a0d12378824","currentValue":"txt","widgetInfo":{"widgetType":"text","name":"SourceFileExtension","defaultValue":"","label":"","options":{"widgetType":"text","validationRegex":null}}}},"notebookOrigID":46311312444427}},"nbformat":4,"nbformat_minor":0}
